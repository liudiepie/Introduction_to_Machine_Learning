{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W6_Reinforcement_Learn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeq4a1HR2wP9zhIg1ZQC11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liudiepie/Introduction_to_Machine_Learning/blob/main/W6_Reinforcement_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkdUR4AxmFnJ"
      },
      "source": [
        "# Introduction to Reinforcement Learning (RL) in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4kJ5nP2mNZW"
      },
      "source": [
        "### Reinforcement Learning\n",
        "Enter Reinforcement Learning. In Reinforcement Learning, our model (commonly referred to as an agent in this context) interacts with an environment by taking actions  𝑎  and receives some sort of feedback from the environment in the form of a reward  𝑟 . In this sense, reinforcement learning algorithms learn by experience. We call the trajectory of going from start to finish of a task an episode, and often our agent will learn by undergoing many episodes.\n",
        "\n",
        "Many reinforcement learning algorithms are modeled as Markov Decision Processes (MDPs). In these settings, we have a concept of a state  𝑠 , which encapsulates the situation of the agent (e.g. location, velocity). From each state  𝑠𝑡 , the agent takes an action  𝑎𝑡 , which results in a transition from one state  𝑠𝑡  to another  𝑠𝑡+1 . In many settings, there is stochasticity in this transition, meaning that there's is a distribution over  𝑠𝑡+1  conditioned on  𝑠𝑡  and  𝑎𝑡 . Often, several of these states are considered episode ending, after which the agent can no longer make any transitions or collect any more reward. These correspond to states such as reaching the final goal, a game concluding, or falling of a cliff. In the end, our goal is to learn a policy  𝜋 , or a mapping from states to actions.\n",
        "\n",
        "In an MDP, we assume that we can always tell which state  𝑠𝑡  our agents is in. However, this isn't always the case. Sometimes, all we have access to are observations  𝑜𝑡  that provide information the state  𝑠𝑡 , but enough to precisely pinpoint the exact one. We call such settings Partially Observable Markov Decision Processes (POMDPs). Imagine for example a Roomba being trained to navigate a living room with RL. From its infrared and mechanical \"bump\" sensors, it receives partial information ( 𝑜𝑡 ) as to where it might be, but not a definitive location ( 𝑠𝑡 ). Operating as a POMDP adds a whole layer of complexity to RL algorithms. For the rest of day though, we'll focus on MDPs, as their much simpler and easier to use to teach basic concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ym_5AjYmkfW"
      },
      "source": [
        "### Open AI Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnYbUaHYmnEU",
        "outputId": "51072c72-3468-4c0b-e189-91823cf64a10"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZzWX0OVmroJ"
      },
      "source": [
        "import gym"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sit_6Jyqm3-5"
      },
      "source": [
        "### ForzenLake (a Grid World)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IVNsb1mm9XM"
      },
      "source": [
        "Let's start with a simple environment: FrozenLake.\n",
        "Here's the official description from OpenAI gym:\n",
        "\n",
        "> *Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend.*\n",
        "\n",
        "A visualization of FrozenLake as a grid world:\n",
        "\n",
        "<img src=\"Figures/FrozenLake.PNG\" alt=\"FrozenLake\" style=\"width: 400px;\"/>\n",
        "\n",
        "At the start of an episode, we begin in the upper left corner (S).\n",
        "Our goal is to move ourself to the lower right corner (G), avoiding falling into the holes (H).\n",
        "Icy water is cold.\n",
        "\n",
        "In reinforcement learning terms, each of the 16 locations on the grid are a state, and an action is attempting to move in one of four directions (left, down, right, up).\n",
        "Each move will result in the agent's state changing from $s_t$ to $s_{t+1}$ as it changes location, unless it attempts to move in the direction of a wall, which results in the agent's state not changing (the agent doesn't move).\n",
        "We receive a positive reward of \"+1\" for reaching the goal (G), discounted according to how long it took.\n",
        "While there is not a negative reward for falling into a hole (H), the agent still pays a penalty in the sense that falling into the hole is episode-ending and therefore prevents it from receiving any reward. \n",
        "We want to learn a policy $\\pi$ that takes us from our starting location (S) to the goal (G) in as few steps as possible.\n",
        "\n",
        "To really establish what we are trying to accomplish here, it's worth debunking a few common initial misconceptions:\n",
        "\n",
        "- **Knowledge of the states and transition probabilties:** From the top-down view, your first thought might be to plot out a path from the start to the finish, just as you would with a maze.\n",
        "However, this view is provided to us the algorithm designers so we can visualize the problem at hand.\n",
        "The agent learning the task does *not* get this prior knowledge; all we are about to tell it is that there are going to be 16 states and 4 possible actions from each state.\n",
        "A more proper analogy would be if I blindfolded you and dropped you in the middle of a frozen lake, and told you your state (location) every time you decided to take a step in one of four directions, then set off fireworks when you stepped on the frisbee.\n",
        "\n",
        "- **Knowledge of the goal (reward):** In OpenAI's official description of the environment, you (the agent) know what you're hoping to accomplish: You want to retrieve the frisbee, while avoiding falling through the ice.\n",
        "The agent does *not* know this.\n",
        "Rather, it learns the goal by experiencing rewards (or penalties), and the algorithm updates its policy such that it will be more (or less) likely to do those actions again.\n",
        "Note that this means that if an agent never experiences certain rewards, it won't know they exist.\n",
        "\n",
        "- **Prior knowledge of pathfinding, physics, etc.:** As a human, even if you haven't solved this task before, you still bring a tremondous amount of prior knowledge to this problem.\n",
        "For example, you know the shortest path to a destination is a line.\n",
        "You know that North, South, East, and West, are directions, and that going North and then South brings you back to where you already were.\n",
        "You know ice is slippery.\n",
        "You know icy water is cold.\n",
        "You know being in icy cold water is bad.\n",
        "It's important to keep in mind that our agent will begin knowing none of these things; it's initial policy is essentially picking actions completely at random.\n",
        "By the end of the training, it still won't know what abstract concepts like \"North/South,\" \"cold,\" or \"slippery\" mean, but it will have (hopefully) learned a good policy that allows it to complete the goal.\n",
        "\n",
        "#### Interacting with FrozenLake\n",
        "This example is simple enough that we could code the environment and its interface ourselves fairly easily, but OpenAI has already done it, and we'd like to focus on the algorithm of solving it as much as possible.\n",
        "We can create an instantiation of FrozenLake in a single line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SA3Bzqar3m0",
        "outputId": "5a90d444-bbd7-44fd-e13d-174d83359328"
      },
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "env.observation_space\n",
        "env.action_space\n",
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ZqkgFXsnF3",
        "outputId": "079752f4-836f-4ed8-a0e5-edea0e784e36"
      },
      "source": [
        "# Non-slippery version\n",
        "\n",
        "from gym.envs.registration import register\n",
        "register(\n",
        "    id='FrozenLakeNotSlippery-v0',\n",
        "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
        ")\n",
        "env = gym.make('FrozenLakeNotSlippery-v0')\n",
        "env.reset()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2ToDLbBsqtN",
        "outputId": "9019304b-8d27-491b-9f0b-633a8121a427"
      },
      "source": [
        "env.step(0)\n",
        "env.render()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgP1-N86tBB9",
        "outputId": "57d67918-4863-4527-a112-9db8836560a6"
      },
      "source": [
        "env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    env.render()\n",
        "    action = env.action_space.sample()\n",
        "    _, _, done, _ = env.step(action)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vD7iH2jtPow"
      },
      "source": [
        "Hm. \n",
        "Not great. \n",
        "Alright, so clearly picking random steps isn't very likely to take us to the goal.\n",
        "It's apparent just from looking at the map that there're much better policies that we can learn.\n",
        "How are we going to do so?\n",
        "\n",
        "#### Q-learning\n",
        "There are many algorithms that we can use, but let's choose Q-learning, which we covered earlier today.\n",
        "Remember, in Q-learning (and SARSA, it turns out), we're trying learn the Q values for the states in our system.\n",
        "\n",
        "The Q value for a policy $\\pi$ is a function of the state $s$ and action $a$ and is defined as the following:\n",
        "\\begin{equation}\n",
        "Q_\\pi (s,a) = \\mathbb{E}\\big[\\sum_{t=0}^{\\infty} \\gamma^t r_t \\big|\\pi, s_0 = s, a_0 = a\\big]\n",
        "\\end{equation}\n",
        "Intuitively, the Q value is the total reward (including discounting) that the agent will gain if it takes action $a$ from state $s$ and then follows policy $\\pi$ for the rest of the episode.\n",
        "As one might expect, if Q is known exactly, the agent will attain the highest reward from $s$ if the policy $\\pi$ is to pick the $a$ with the highest Q value.\n",
        "\n",
        "Okay, so if we know the Q values for the system, then we can trivially find the optimal policy.\n",
        "So what are the Q values of the system?\n",
        "Well, at the beginning, we don't know, but we can try to learn them through experience.\n",
        "This is where Q-learning comes in.\n",
        "Q-learning iteratively updates the Q values in the following way:\n",
        "\\begin{equation}\n",
        "Q_\\pi (s_t, a_t) \\leftarrow (1 - \\alpha) \\cdot Q_\\pi(s_t, a_t) + \\alpha \\cdot \\big(r_t + \\gamma \\max_a Q_\\pi(s_{t+1}, a)\\big)\n",
        "\\end{equation}\n",
        "Notice that Q-learning is an *off-policy* method, in the sense that you don't actually learn from the trajectory you actually took (otherwise it'd be SARSA).\n",
        "Instead, we learn from the *greedy* transition, i.e. the best action we know how to take.\n",
        "\n",
        "And that's it! \n",
        "We run our agent through many episodes, experiencing many $s_t \\rightarrow a_t \\rightarrow s_{t+1}$ transitions and rewards, and just like that, we eventually learn a good Q function (and thus a good policy).\n",
        "Now of course, there are a bunch of small details and tweaks to make this work in practice, but we'll get to those later.\n",
        "\n",
        "#### Q-learning in FrozenLake\n",
        "FrozenLake is a very simple setting, one that we would call a toy problem.\n",
        "With only 16 states and 4 actions, there are only 64 state-action pairs possible (16x4=64), less if we account for the goal and the holes being episode ending (for simplicity though, we won't). \n",
        "With this few state-action pairs, we can actually solve this problem tabularly.\n",
        "Let's set up a Q table, and initialize the Q-values for all state-action pairs to zeros.\n",
        "Note that while we could, we're actually not going to need PyTorch in this example; PyTorch's autograd and neural network libraries are unnecessary here, as we're only going to be modifying a table of numbers.\n",
        "Instead, we'll use a Numpy array to store the Q table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Pl2FuPtgWY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Initialize table with all zeros to be uniform\n",
        "Q = np.zeros([env.observation_space.n, env.action_space.n])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgFKS8ALtj2x"
      },
      "source": [
        "A few hyperparameters we're going to set:\n",
        "- `alpha`: learning rate for the Q function\n",
        "- `gamma`: discount rate for future rewards\n",
        "- `num_episodes`: number of episodes (trajectories from start to goal/hole) our agent will learn from\n",
        "\n",
        "We're also going to store our rewards in an array called `rs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCrL2uqAtp9D"
      },
      "source": [
        "# Learning parameters\n",
        "alpha = 0.1\n",
        "gamma = 0.95\n",
        "num_episodes = 2000\n",
        "\n",
        "# array of reward for each episode\n",
        "rs = np.zeros([num_episodes])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGuxOyK5twvz"
      },
      "source": [
        "for i in range(num_episodes):\n",
        "    # Set total reward and time to zero, done to False\n",
        "    r_sum_i = 0\n",
        "    t = 0\n",
        "    done = False\n",
        "    \n",
        "    #Reset environment and get first new observation\n",
        "    s = env.reset()\n",
        "    \n",
        "    while not done:\n",
        "        # Choose an action by greedily (with noise) from Q table\n",
        "        a = np.argmax(Q[s,:] + np.random.randn(1, env.action_space.n)*(1./(i/10+1)))\n",
        "        \n",
        "        # Get new state and reward from environment\n",
        "        s1, r, done, _ = env.step(a)\n",
        "        \n",
        "        # Update Q-Table with new knowledge\n",
        "        Q[s,a] = (1 - alpha)*Q[s,a] + alpha*(r + gamma*np.max(Q[s1,:]))\n",
        "        \n",
        "        # Add reward to episode total\n",
        "        r_sum_i += r*gamma**t\n",
        "        \n",
        "        # Update state and time\n",
        "        s = s1\n",
        "        t += 1\n",
        "    rs[i] = r_sum_i"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "jCSdTvEa09wY",
        "outputId": "a39623c6-4c4f-43dd-faff-e2756f1182a0"
      },
      "source": [
        "## Plot reward vs episodes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sliding window average\n",
        "r_cumsum = np.cumsum(np.insert(rs, 0, 0)) \n",
        "r_cumsum = (r_cumsum[50:] - r_cumsum[:-50]) / 50\n",
        "\n",
        "# Plot\n",
        "plt.plot(r_cumsum)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFcwxWXG1AUr",
        "outputId": "8b9a1fd2-5cf8-4af6-c373-d599de942dfa"
      },
      "source": [
        "# Print number of times the goal was reached\n",
        "N = len(rs)//10\n",
        "num_Gs = np.zeros(10)\n",
        "\n",
        "for i in range(10):\n",
        "    num_Gs[i] = np.sum(rs[i*N:(i+1)*N] > 0)\n",
        "    \n",
        "print(\"Rewards: {0}\".format(num_Gs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rewards: [  3. 161. 200. 200. 200. 200. 200. 200. 200. 200.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jQu4SCz1Iki"
      },
      "source": [
        "### PyTorch in RL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If5h6U8-1LP2"
      },
      "source": [
        "### Cart Pole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "1OY4AkN56Nkw",
        "outputId": "f58baa9f-fc45-42f1-a911-7d4ce83b732e"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install colabgymrender==1.0.2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colabgymrender==1.0.2\n",
            "  Downloading colabgymrender-1.0.2.tar.gz (1.8 kB)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (from colabgymrender==1.0.2) (2.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from colabgymrender==1.0.2) (0.2.3.5)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from colabgymrender==1.0.2) (0.17.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from colabgymrender==1.0.2) (4.1.2.30)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->colabgymrender==1.0.2) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->colabgymrender==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym->colabgymrender==1.0.2) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->colabgymrender==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->colabgymrender==1.0.2) (0.16.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender==1.0.2) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender==1.0.2) (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender==1.0.2) (7.1.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay->colabgymrender==1.0.2) (0.3)\n",
            "Building wheels for collected packages: colabgymrender\n",
            "  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabgymrender: filename=colabgymrender-1.0.2-py3-none-any.whl size=2445 sha256=e35763987af5f811ef6bf500ac6ff2a50848dbaf624574b81389775ed75a0580\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/56/73/3697080da5fc7b120516aef37d1d1eb2380515ba9e272b8ccd\n",
            "Successfully built colabgymrender\n",
            "Installing collected packages: colabgymrender\n",
            "  Attempting uninstall: colabgymrender\n",
            "    Found existing installation: colabgymrender 1.0.9\n",
            "    Uninstalling colabgymrender-1.0.9:\n",
            "      Successfully uninstalled colabgymrender-1.0.9\n",
            "Successfully installed colabgymrender-1.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "colabgymrender"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "XbLofuIA1Rhy",
        "outputId": "74b4d710-7532-4b82-ec98-b4ddf65c71f8"
      },
      "source": [
        "import gym\n",
        "from colabgymrender.recorder import Recorder\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "env = Recorder(env, '/.video')\n",
        "\n",
        "observation = env.reset()\n",
        "terminal = False\n",
        "while not terminal:\n",
        "  action = env.action_space.sample()\n",
        "  observation, reward, terminal, info = env.step(action)\n",
        "\n",
        "env.play()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 33/34 [00:00<00:00, 241.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div align=middle><video width='400' height='600'src='data:video/mp4;base64,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' controls>Sorry, seems like your browser doesn't support HTML5 audio/video</video></div>"
            ],
            "text/plain": [
              "<moviepy.video.io.html_tools.HTML2 object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnE3GR6y1b3F"
      },
      "source": [
        "env.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNm4b9kf1fsb",
        "outputId": "0ce91d01-45b5-46dd-e80c-3db737626869"
      },
      "source": [
        "# Based on: https://gym.openai.com/evaluations/eval_EIcM1ZBnQW2LBaFN6FY65g/\n",
        "\n",
        "from collections import deque\n",
        "import random\n",
        "import math\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(4, 24)\n",
        "        self.fc2 = nn.Linear(24, 48)\n",
        "        self.fc3 = nn.Linear(48, 2)\n",
        "\n",
        "    def forward(self, x):        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x        \n",
        "    \n",
        "\n",
        "class DQNCartPoleSolver:\n",
        "    def __init__(self, n_episodes=1000, n_win_ticks=195, max_env_steps=None, gamma=1.0, epsilon=1.0, epsilon_min=0.01, epsilon_log_decay=0.995, alpha=0.01, alpha_decay=0.01, batch_size=64, monitor=False, quiet=False):\n",
        "        self.memory = deque(maxlen=100000)\n",
        "        self.env = gym.make('CartPole-v0')\n",
        "        if monitor: self.env = gym.wrappers.Monitor(self.env, '../data/cartpole-1', force=True)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_log_decay\n",
        "        self.alpha = alpha\n",
        "        self.alpha_decay = alpha_decay\n",
        "        self.n_episodes = n_episodes\n",
        "        self.n_win_ticks = n_win_ticks\n",
        "        self.batch_size = batch_size\n",
        "        self.quiet = quiet\n",
        "        if max_env_steps is not None: self.env._max_episode_steps = max_env_steps\n",
        "\n",
        "        # Init model\n",
        "        self.dqn = DQN()\n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.opt = torch.optim.Adam(self.dqn.parameters(), lr=0.01)\n",
        "\n",
        "    def get_epsilon(self, t):\n",
        "        return max(self.epsilon_min, min(self.epsilon, 1.0 - math.log10((t + 1) * self.epsilon_decay)))\n",
        "\n",
        "    def preprocess_state(self, state):\n",
        "        return torch.tensor(np.reshape(state, [1, 4]), dtype=torch.float32) \n",
        "    \n",
        "    def choose_action(self, state, epsilon):\n",
        "        if (np.random.random() <= epsilon):\n",
        "            return self.env.action_space.sample() \n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                return torch.argmax(self.dqn(state)).numpy()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        reward = torch.tensor(reward)\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "    \n",
        "    def replay(self, batch_size):\n",
        "        y_batch, y_target_batch = [], []\n",
        "        minibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            y = self.dqn(state)\n",
        "            y_target = y.clone().detach()\n",
        "            with torch.no_grad():\n",
        "                y_target[0][action] = reward if done else reward + self.gamma * torch.max(self.dqn(next_state)[0])\n",
        "            y_batch.append(y[0])\n",
        "            y_target_batch.append(y_target[0])\n",
        "        \n",
        "        y_batch = torch.cat(y_batch)\n",
        "        y_target_batch = torch.cat(y_target_batch)\n",
        "        \n",
        "        self.opt.zero_grad()\n",
        "        loss = self.criterion(y_batch, y_target_batch)\n",
        "        loss.backward()\n",
        "        self.opt.step()        \n",
        "        \n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def run(self):\n",
        "        scores = deque(maxlen=100)\n",
        "\n",
        "        for e in range(self.n_episodes):\n",
        "            state = self.preprocess_state(self.env.reset())\n",
        "            done = False\n",
        "            i = 0\n",
        "            while not done:\n",
        "                if e % 100 == 0 and not self.quiet:\n",
        "                    self.env.render()\n",
        "                action = self.choose_action(state, self.get_epsilon(e))\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                next_state = self.preprocess_state(next_state)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                i += 1\n",
        "\n",
        "            scores.append(i)\n",
        "            mean_score = np.mean(scores)\n",
        "            if mean_score >= self.n_win_ticks and e >= 100:\n",
        "                if not self.quiet: print('Ran {} episodes. Solved after {} trials ✔'.format(e, e - 100))\n",
        "                return e - 100\n",
        "            if e % 100 == 0 and not self.quiet:\n",
        "                print('[Episode {}] - Mean survival time over last 100 episodes was {} ticks.'.format(e, mean_score))\n",
        "\n",
        "            self.replay(self.batch_size)\n",
        "        \n",
        "        if not self.quiet: print('Did not solve after {} episodes 😞'.format(e))\n",
        "        return e\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    agent = DQNCartPoleSolver()\n",
        "    agent.run()\n",
        "    agent.env.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Episode 0] - Mean survival time over last 100 episodes was 20.0 ticks.\n",
            "[Episode 100] - Mean survival time over last 100 episodes was 13.36 ticks.\n",
            "[Episode 200] - Mean survival time over last 100 episodes was 41.25 ticks.\n",
            "[Episode 300] - Mean survival time over last 100 episodes was 58.72 ticks.\n",
            "[Episode 400] - Mean survival time over last 100 episodes was 140.74 ticks.\n",
            "[Episode 500] - Mean survival time over last 100 episodes was 158.73 ticks.\n",
            "[Episode 600] - Mean survival time over last 100 episodes was 186.52 ticks.\n",
            "[Episode 700] - Mean survival time over last 100 episodes was 150.15 ticks.\n",
            "[Episode 800] - Mean survival time over last 100 episodes was 36.96 ticks.\n",
            "[Episode 900] - Mean survival time over last 100 episodes was 9.44 ticks.\n",
            "Did not solve after 999 episodes 😞\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ARUkB6m8fMC"
      },
      "source": [
        "Reinforcement learning can be kind of noisy. In some sense, it depends on your agent \"lucking\" into the right behavior so that it can learn from it, and occasionally one can get stuck in a bad rut. Even if your agent fails to \"solve\" the problem (i.e. reach 200 ticks), you should still see the mean survival time mostly climbing as the agent experiences more episodes. You may need to re-run learning a couple times for the agent to reach 200 ticks."
      ]
    }
  ]
}